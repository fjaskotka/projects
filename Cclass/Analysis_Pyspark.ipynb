{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.10 64-bit"
  },
  "interpreter": {
   "hash": "4cd7ab41f5fca4b9b44701077e38c5ffd31fe66a6cab21e0214b68d958d0e462"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Analysis of C-Class dataset in PySpark"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Loading the data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing necessary packages\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import StructType, StructField\n",
    "from pyspark.sql.types import StringType, IntegerType, DecimalType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType([\n",
    "    StructField('model', StringType()),\n",
    "    StructField('year', IntegerType()),\n",
    "    StructField('price', IntegerType()),\n",
    "    StructField('transmission', StringType()),\n",
    "    StructField('mileage', IntegerType()),\n",
    "    StructField('fuelType', StringType()),\n",
    "    StructField('engineSize', DecimalType())\n",
    "])\n",
    "\n",
    "df = spark.read.csv('cclass.csv', header = True, schema = schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+--------+----+-----+------------+-------+--------+----------+\n|   model|year|price|transmission|mileage|fuelType|engineSize|\n+--------+----+-----+------------+-------+--------+----------+\n| C Class|2020|30495|   Automatic|   1200|  Diesel|         2|\n| C Class|2020|29989|   Automatic|   1000|  Petrol|         2|\n| C Class|2020|37899|   Automatic|    500|  Diesel|         2|\n| C Class|2019|30399|   Automatic|   5000|  Diesel|         2|\n| C Class|2019|29899|   Automatic|   4500|  Diesel|         2|\n| C Class|2020|30999|   Automatic|   1000|  Diesel|         2|\n| C Class|2020|35999|   Automatic|    500|  Diesel|         2|\n| C Class|2019|37990|   Automatic|   1412|  Petrol|         3|\n| C Class|2019|28990|   Automatic|   3569|  Diesel|         2|\n| C Class|2019|28990|   Automatic|   3635|  Diesel|         2|\n| C Class|2013| 9995|   Automatic|  44900|  Petrol|         2|\n| C Class|2012| 6995|   Automatic|  88200|  Diesel|         2|\n| C Class|2012| 7495|   Automatic| 115000|  Diesel|         2|\n| C Class|2011| 8995|   Automatic|  69250|  Diesel|         2|\n| C Class|2015|14995|   Automatic|  49850|  Diesel|         2|\n| C Class|2013| 8595|   Automatic|  82685|  Diesel|         2|\n| C Class|2016|19250|   Semi-Auto|  32506|  Diesel|         2|\n| C Class|2017|23500|   Semi-Auto|  17000|  Diesel|         2|\n| C Class|2018|24995|   Semi-Auto|  17744|  Diesel|         2|\n| C Class|2016|29995|   Semi-Auto|  64291|  Petrol|         4|\n+--------+----+-----+------------+-------+--------+----------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('model', 'string'),\n",
       " ('year', 'int'),\n",
       " ('price', 'int'),\n",
       " ('transmission', 'string'),\n",
       " ('mileage', 'int'),\n",
       " ('fuelType', 'string'),\n",
       " ('engineSize', 'decimal(10,0)')]"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+-----+----+-----+------------+-------+--------+----------+\n|model|year|price|transmission|mileage|fuelType|engineSize|\n+-----+----+-----+------------+-------+--------+----------+\n|    0|   0|    0|           0|      0|       0|         0|\n+-----+----+-----+------------+-------+--------+----------+\n\n"
     ]
    }
   ],
   "source": [
    "#examining Missing values\n",
    "df.select([F.count(F.when(F.isnan(c), c)).alias(c)for c in df.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "3899"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+-------+--------+------------------+-----------------+------------+------------------+--------+-------------------+\n|summary|   model|              year|            price|transmission|           mileage|fuelType|         engineSize|\n+-------+--------+------------------+-----------------+------------+------------------+--------+-------------------+\n|  count|    3899|              3899|             3899|        3899|              3899|    3899|               3899|\n|   mean|    null|2017.3385483457296|23674.28699666581|        null|22395.709156193894|    null|             2.1036|\n| stddev|    null|2.2134156573374724| 8960.21821842348|        null|22630.438425876873|    null|0.41648280841854707|\n|    min| C Class|              1991|             1290|   Automatic|                 1|  Diesel|                  0|\n|    25%|    null|              2016|            17690|        null|              6000|    null|                2.0|\n|    50%|    null|              2018|            22980|        null|             14640|    null|                2.0|\n|    75%|    null|              2019|            28900|        null|             32475|    null|                2.0|\n|    max| C Class|              2020|            88995|   Semi-Auto|            173000|  Petrol|                  6|\n+-------+--------+------------------+-----------------+------------+------------------+--------+-------------------+\n\n"
     ]
    }
   ],
   "source": [
    "df.summary().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing neccesary packages\n"
   ]
  },
  {
   "source": [
    "### Dropping model column"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(*'model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+--------+----+-----+------------+-------+--------+----------+\n|   model|year|price|transmission|mileage|fuelType|engineSize|\n+--------+----+-----+------------+-------+--------+----------+\n| C Class|2020|30495|   Automatic|   1200|  Diesel|         2|\n| C Class|2020|29989|   Automatic|   1000|  Petrol|         2|\n| C Class|2020|37899|   Automatic|    500|  Diesel|         2|\n| C Class|2019|30399|   Automatic|   5000|  Diesel|         2|\n| C Class|2019|29899|   Automatic|   4500|  Diesel|         2|\n| C Class|2020|30999|   Automatic|   1000|  Diesel|         2|\n| C Class|2020|35999|   Automatic|    500|  Diesel|         2|\n| C Class|2019|37990|   Automatic|   1412|  Petrol|         3|\n| C Class|2019|28990|   Automatic|   3569|  Diesel|         2|\n| C Class|2019|28990|   Automatic|   3635|  Diesel|         2|\n| C Class|2013| 9995|   Automatic|  44900|  Petrol|         2|\n| C Class|2012| 6995|   Automatic|  88200|  Diesel|         2|\n| C Class|2012| 7495|   Automatic| 115000|  Diesel|         2|\n| C Class|2011| 8995|   Automatic|  69250|  Diesel|         2|\n| C Class|2015|14995|   Automatic|  49850|  Diesel|         2|\n| C Class|2013| 8595|   Automatic|  82685|  Diesel|         2|\n| C Class|2016|19250|   Semi-Auto|  32506|  Diesel|         2|\n| C Class|2017|23500|   Semi-Auto|  17000|  Diesel|         2|\n| C Class|2018|24995|   Semi-Auto|  17744|  Diesel|         2|\n| C Class|2016|29995|   Semi-Auto|  64291|  Petrol|         4|\n+--------+----+-----+------------+-------+--------+----------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "source": [
    "### Examining Skewness"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+------------------+\n|   skewness(price)|\n+------------------+\n|1.2187220652245783|\n+------------------+\n\n"
     ]
    }
   ],
   "source": [
    "df.agg({'price':'skewness'}).show()\n",
    "\n",
    "#If between -0.5 and 0.5 it is fairly symmetrical\n",
    "# if between -1 and 1 it is moderately skwewd\n",
    "#if between smaller than -1 and biger than 1 then highly skwewd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if positively sweked, log transformation can help\n",
    "df = df.withColumn('price_log', F.log10(F.col('price')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "ERROR:root:Exception while sending command.\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.7/site-packages/py4j/java_gateway.py\", line 1207, in send_command\n    raise Py4JNetworkError(\"Answer from Java side is empty\")\npy4j.protocol.Py4JNetworkError: Answer from Java side is empty\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.7/site-packages/py4j/java_gateway.py\", line 1033, in send_command\n    response = connection.send_command(command)\n  File \"/usr/local/lib/python3.7/site-packages/py4j/java_gateway.py\", line 1212, in send_command\n    \"Error while receiving\", e, proto.ERROR_ON_RECEIVE)\npy4j.protocol.Py4JNetworkError: Error while receiving\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "Py4JError",
     "evalue": "An error occurred while calling o445.showString",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-1a6ce2362cd4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(self, n, truncate, vertical)\u001b[0m\n\u001b[1;32m    482\u001b[0m         \"\"\"\n\u001b[1;32m    483\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtruncate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtruncate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 484\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvertical\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    485\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtruncate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvertical\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1303\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1305\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1307\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mconverted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    334\u001b[0m             raise Py4JError(\n\u001b[1;32m    335\u001b[0m                 \u001b[0;34m\"An error occurred while calling {0}{1}{2}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 336\u001b[0;31m                 format(target_id, \".\", name))\n\u001b[0m\u001b[1;32m    337\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m         \u001b[0mtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPy4JError\u001b[0m: An error occurred while calling o445.showString"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "source": [
    "## Normalization of Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Min Max Scaler\n",
    "from pyspark.ml.feature import MinMaxScaler\n",
    "\n",
    "#First VectorAssembler\n",
    "#Then MinMaxScaler\n",
    "#pipelining\n",
    "# Iterating over columns to be scaled\n",
    "for i in [\"Revenue\",\"No_of_Days\"]:\n",
    "    # VectorAssembler Transformation - Converting column to vector type\n",
    "    assembler = VectorAssembler(inputCols=[i],outputCol=i+\"_Vect\")\n",
    "\n",
    "    # MinMaxScaler Transformation\n",
    "    scaler = MinMaxScaler(inputCol=i+\"_Vect\", outputCol=i+\"_Scaled\")\n",
    "\n",
    "    # Pipeline of VectorAssembler and MinMaxScaler\n",
    "    pipeline = Pipeline(stages=[assembler, scaler])\n",
    "\n",
    "    # Fitting pipeline on dataframe\n",
    "    df = pipeline.fit(df).transform(df).withColumn(i+\"_Scaled\", unlist(i+\"_Scaled\")).drop(i+\"_Vect\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fabi Normalization function\n",
    "\n",
    "# Function to normalise dataframes\n",
    "def standardize_train_test_data(train_df, test_df, columns):\n",
    "    '''\n",
    "    Add normalised columns to the input dataframe.\n",
    "    formula = [(X - mean) / std_dev]\n",
    "    Inputs : training dataframe, list of column name strings to be normalised\n",
    "    Returns : dataframe with new normalised columns, averages and std deviation dataframes \n",
    "    '''\n",
    "    # Find the Mean and the Standard Deviation for each column\n",
    "    aggExpr = []\n",
    "    aggStd = []\n",
    "    for column in columns:\n",
    "        aggExpr.append(mean(train_df[column]).alias(column))\n",
    "        aggStd.append(stddev(train_df[column]).alias(column + '_stddev'))\n",
    "    \n",
    "    averages = train_df.agg(*aggExpr).collect()[0]\n",
    "    std_devs = train_df.agg(*aggStd).collect()[0]\n",
    "    \n",
    "    # Standardise each dataframe, column by column\n",
    "    for column in columns:            \n",
    "        # Standardise the TRAINING data\n",
    "        train_df = train_df.withColumn(column + '_norm', ((train_df[column] - averages[column]) / \n",
    "                                                              std_devs[column + '_stddev']))       \n",
    "    \n",
    "        # Standardise the TEST data (using the training mean and std_dev)     \n",
    "        test_df = test_df.withColumn(column + '_norm', ((test_df[column] - averages[column]) / \n",
    "                                                              std_devs[column + '_stddev']))  \n",
    "    return train_df, test_df, averages, std_devs\n"
   ]
  }
 ]
}